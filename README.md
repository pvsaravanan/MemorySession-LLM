# ğŸ§  MemorySession-LLM

A conversational Streamlit chatbot app powered by local (Ollama) and cloud (OpenRouter) LLMs with session memory and a toggleable "Think Harder" mode.

---

## ğŸš€ Features

- ğŸ’¬ Chat interface with real-time streaming responses
- ğŸ§  Session memory for context-aware conversation
- ğŸ” Toggle between small (local) and large (cloud) models
- ğŸ¨ Custom-styled dark mode UI with improved readability
- ğŸŒ Supports OpenRouter (e.g. DeepSeek) and Ollama (e.g. Gemma)

---

## ğŸ›  Tech Stack

- [LangChain](https://github.com/langchain-ai/langchain)
- [LangChain Community](https://github.com/langchain-ai/langchain-community)
- [Streamlit](https://streamlit.io/)
- [Ollama](https://ollama.ai/) (Local model runner)
- [OpenRouter](https://openrouter.ai/) (API gateway for open models)
- [Python dotenv](https://pypi.org/project/python-dotenv/)

---

## ğŸ“ Project Structure

```
MemorySession-LLM/
â”‚
â”œâ”€â”€ app.py                # Main Streamlit 
â”œâ”€â”€ .env                  # Environment variables (model names, API keys)
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project overview
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the repo
```bash
git clone https://github.com/your-username/MemorySession-LLM.git
cd MemorySession-LLM
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Setup `.env`
Create a `.env` file with the following:
```env
LOCAL_BASE_URL=http://localhost:11434/v1
REMOTE_BASE_URL=https://openrouter.ai/api/v1
LOCAL_MODEL_NAME=<model_name>
REMOTE_MODEL_NAME=<model_name>
OPENROUTER_API_KEY=your-openrouter-api-key
```

### 4. Run Ollama locally
Install and start Ollama:
```bash
ollama run <model_name>
```

### 5. Launch the app
```bash
streamlit run app.py
```

---

## ğŸ“¸ UI Preview

![Chat UI Demo](screenshot.png) <!-- Replace with your image path -->

---

## ğŸ§ª Example Prompts

- "Summarize the Industrial Revolution."
- "What is the capital of Japan?"
- "Write a Python function to sort a list of dictionaries."

---

## ğŸ“Œ Notes

- You can toggle between small (Ollama) and large (OpenRouter) models using the **â€œThink harder...â€** checkbox.
- Ensure Ollama is running before using local models.

---

## ğŸ“„ License

MIT License Â© 2025 Saravanan PV
